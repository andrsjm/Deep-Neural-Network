{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e184fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.model_selection import learning_curve\n",
    "from math import sqrt\n",
    "from numpy.random import randn\n",
    "import pickle\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fefa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_2020_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd110be1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>16.60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>55-59</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>20.34</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>80 or older</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>26.58</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>65-69</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fair</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>24.21</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>75-79</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Good</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>23.71</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>40-44</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very good</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HeartDisease    BMI Smoking AlcoholDrinking Stroke  PhysicalHealth  \\\n",
       "0           No  16.60     Yes              No     No             3.0   \n",
       "1           No  20.34      No              No    Yes             0.0   \n",
       "2           No  26.58     Yes              No     No            20.0   \n",
       "3           No  24.21      No              No     No             0.0   \n",
       "4           No  23.71      No              No     No            28.0   \n",
       "\n",
       "   MentalHealth DiffWalking     Sex  AgeCategory   Race Diabetic  \\\n",
       "0          30.0          No  Female        55-59  White      Yes   \n",
       "1           0.0          No  Female  80 or older  White       No   \n",
       "2          30.0          No    Male        65-69  White      Yes   \n",
       "3           0.0          No  Female        75-79  White       No   \n",
       "4           0.0         Yes  Female        40-44  White       No   \n",
       "\n",
       "  PhysicalActivity  GenHealth  SleepTime Asthma KidneyDisease SkinCancer  \n",
       "0              Yes  Very good        5.0    Yes            No        Yes  \n",
       "1              Yes  Very good        7.0     No            No         No  \n",
       "2              Yes       Fair        8.0    Yes            No         No  \n",
       "3               No       Good        6.0     No            No        Yes  \n",
       "4              Yes  Very good        8.0     No            No         No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e008f",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdac0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def label_encoding(self, columns):\n",
    "        label_encoder = LabelEncoder()\n",
    "        for column in columns:\n",
    "            self.df[column]= label_encoder.fit_transform(self.df[column])\n",
    "            self.df[column].unique()\n",
    "    \n",
    "    def clean_outliers(self, columns):\n",
    "        for column in columns:   \n",
    "            q1, q3 = self.df[column].quantile([0.25, 0.75])\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            self.df = self.df[(self.df[column] <= upper_bound )]\n",
    "            self.df = self.df[(self.df[column] >= lower_bound )]\n",
    "    \n",
    "    def missing_value(self):\n",
    "        self.df=self.df.dropna()\n",
    "        \n",
    "    def duplicated_data(self):\n",
    "        self.df = self.df.drop_duplicates()\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "    \n",
    "    def set_df(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def min_max_scaller(self, X):\n",
    "        # define min max scaler\n",
    "        scaler = MinMaxScaler()\n",
    "        # transform data\n",
    "        scaled = scaler.fit_transform(X)\n",
    "        return scaled\n",
    "    \n",
    "    def split_dataset(self, X, y, test_size=0.2, random_state=42):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b926a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = PreProcessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7af675",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.label_encoding(['HeartDisease', 'Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking', 'Sex', 'AgeCategory', 'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'Asthma', 'KidneyDisease', 'SkinCancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d971886",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.duplicated_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1778cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.clean_outliers(['BMI', 'PhysicalHealth', 'MentalHealth', 'SleepTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89802c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.missing_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6cae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pp.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135d0e18",
   "metadata": {},
   "source": [
    "## Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c57df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chi_square:\n",
    "    def __init__(self, df, target):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "       \n",
    "    \n",
    "    def count_chi_square(self):\n",
    "        x = list(self.df.columns.values) #mengambil semua column di dataframe\n",
    "        x.remove(self.target)  #menghapus nama dataframe yang sama dengan target\n",
    "        \n",
    "        chi_square = {}      \n",
    "        \n",
    "        for k in x:\n",
    "            expected_table = []\n",
    "            temp_table = pd.crosstab(self.df[k], self.df[self.target], margins = True)\n",
    "            observed_table = temp_table.to_numpy() #membuat observed table\n",
    "\n",
    "            #menhitung nilai expected value\n",
    "            for i in range (len(observed_table)-1):\n",
    "                expected_value = []\n",
    "                for j in range (len(observed_table[0])-1):\n",
    "                    temp_1 = (observed_table[i][len(observed_table[0])-1] * observed_table[len(observed_table)-1][j])\n",
    "                    temp_2 = observed_table[len(observed_table)-1][len(observed_table[0])-1]\n",
    "                    temp_expected_value = temp_1 / temp_2\n",
    "                    expected_value.append(temp_expected_value)\n",
    "                expected_table.append(expected_value)\n",
    "\n",
    "            #menghitung nilai chi-square\n",
    "            chi_square_value = 0\n",
    "            for i in range (len(expected_table)):\n",
    "                for j in range (len(expected_table[0])):\n",
    "                    temp = ((observed_table[i][j] - expected_table[i][j])**2) / expected_table[i][j]\n",
    "                    chi_square_value += temp\n",
    "            chi_square[k] = chi_square_value \n",
    "\n",
    "        return chi_square        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04dae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chi_square = df[['Smoking', 'AlcoholDrinking', 'Stroke', 'Diabetic', 'DiffWalking', 'PhysicalActivity', 'Asthma', 'KidneyDisease', 'SkinCancer', 'Sex', 'AgeCategory', 'HeartDisease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ab09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = Chi_square(df_chi_square, 'HeartDisease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8257292",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = cs.count_chi_square()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "799f5f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Smoking': 1845.0182293406463,\n",
       " 'AlcoholDrinking': 221.84641477922702,\n",
       " 'Stroke': 5120.790248274026,\n",
       " 'Diabetic': 4864.25194067944,\n",
       " 'DiffWalking': 3894.0079814240444,\n",
       " 'PhysicalActivity': 626.8355415890005,\n",
       " 'Asthma': 48.37346199737936,\n",
       " 'KidneyDisease': 2529.212721093091,\n",
       " 'SkinCancer': 1672.4888796522578,\n",
       " 'Sex': 1487.2612205040882,\n",
       " 'AgeCategory': 12926.826885659233}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc85020",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['AlcoholDrinking', 'PhysicalActivity', 'Asthma', 'HeartDisease', 'SkinCancer', 'Sex'])\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68ca7b",
   "metadata": {},
   "source": [
    "## Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "455046de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomUnderSampling:\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state=random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        undersample = RandomUnderSampler(random_state=self.random_state)\n",
    "        X_under, y_under = undersample.fit_resample(X, y)\n",
    "        return X_under, y_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bb22468",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampling(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e247f7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_under, y_under = undersample.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0a790",
   "metadata": {},
   "source": [
    "## Data Splitting & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dae7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pp.split_dataset(X_under, y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f36c9fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb37a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pp.min_max_scaller(X_train)\n",
    "X_test_scaled = pp.min_max_scaller(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8be4b6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wadidaw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17344\\2315058665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwadidaw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wadidaw' is not defined"
     ]
    }
   ],
   "source": [
    "wadidaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ec9d4",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "849ea183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activator; we ask if we want the sigmoid or its derivative\n",
    "def sigmoid_act(x, der=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if (der==True) : #derivative of the sigmoid\n",
    "        f = 1/(1+ np.exp(- x))*(1-1/(1+ np.exp(- x)))\n",
    "    else : # sigmoid\n",
    "        f = 1/(1+ np.exp(- x))\n",
    "    \n",
    "    return f\n",
    "\n",
    "# We may employ the Rectifier Linear Unit (ReLU)\n",
    "def ReLU_act(x, der=False):\n",
    "    import numpy as np\n",
    "    \n",
    "    if (der == True): # the derivative of the ReLU is the Heaviside Theta\n",
    "        f = np.heaviside(x, 1)\n",
    "    else :\n",
    "        f = np.maximum(x, 0)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "febaedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Artificial Neural Network Class\n",
    "'''\n",
    "class DeepNeuralNetwork:\n",
    "    import numpy as np # linear algebra\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    '''\n",
    "    Initialize the ANN;\n",
    "    HiddenLayer vector : will contain the Layers' info\n",
    "    w, b, phi = (empty) arrays that will contain all the w, b and activation functions for all the Layers\n",
    "    mu = cost function\n",
    "    eta = a standard learning rate initialization. It can be modified by the 'set_learning_rate' method\n",
    "    '''\n",
    "    def __init__(self) :\n",
    "        self.HiddenLayer = []\n",
    "        self.w = []\n",
    "        self.b = []\n",
    "        self.phi = []\n",
    "        self.mu = []\n",
    "        self.eta = 1 #set up the proper Learning Rate!!\n",
    "    \n",
    "    '''\n",
    "    add method: to add layers to the network\n",
    "    '''\n",
    "    def add(self, lay = (4, 'ReLU') ):\n",
    "        self.HiddenLayer.append(lay)\n",
    "    \n",
    "    '''\n",
    "    FeedForward method: as explained before. \n",
    "    '''\n",
    "    @staticmethod\n",
    "    def FeedForward(w, b, phi, x):\n",
    "        return phi(np.dot(w, x) + b)\n",
    "        \n",
    "    '''\n",
    "    BackPropagation algorithm implementing the Gradient Descent \n",
    "    '''\n",
    "    def BackPropagation(self, x, z, Y, w, b, phi):\n",
    "        self.delta = []\n",
    "        \n",
    "        # We initialize ausiliar w and b that are used only inside the backpropagation algorithm once called        \n",
    "        self.W = []\n",
    "        self.B = []\n",
    "        \n",
    "        # We start computing the LAST error, the one for the OutPut Layer \n",
    "        self.delta.append(  (z[len(z)-1] - Y) * phi[len(z)-1](z[len(z)-1], der=True) )\n",
    "        \n",
    "        '''Now we BACKpropagate'''\n",
    "        # We thus compute from next-to-last to first\n",
    "        for i in range(0, len(z)-1):\n",
    "            self.delta.append( np.dot( self.delta[i], w[len(z)- 1 - i] ) * phi[len(z)- 2 - i](z[len(z)- 2 - i], der=True) )\n",
    "        \n",
    "        # We have the error array ordered from last to first; we flip it to order it from first to last\n",
    "        temp_delta = []\n",
    "        for i in reversed(self.delta):\n",
    "            temp_delta.append(i)\n",
    "            \n",
    "        self.delta = np.array(temp_delta, dtype=object)\n",
    "        \n",
    "        # Now we define the delta as the error divided by the number of training samples\n",
    "        self.delta = self.delta/self.X.shape[0] \n",
    "        \n",
    "        '''GRADIENT DESCENT'''\n",
    "        # We start from the first layer that is special, since it is connected to the Input Layer\n",
    "        self.W.append( w[0] - self.eta * np.kron(self.delta[0], x).reshape( len(z[0]), x.shape[0] ) )\n",
    "        self.B.append( b[0] - self.eta * self.delta[0] )\n",
    "        \n",
    "        # We now descend for all the other Hidden Layers + OutPut Layer\n",
    "        for i in range(1, len(z)):\n",
    "            self.W.append( w[i] - self.eta * np.kron(self.delta[i], z[i-1]).reshape(len(z[i]), len(z[i-1])) )\n",
    "            self.B.append( b[i] - self.eta * self.delta[i] )\n",
    "        \n",
    "        # We return the descended parameters w, b\n",
    "        np.warnings.filterwarnings('error', category=np.VisibleDeprecationWarning)\n",
    "        return np.array(self.W, dtype=object), np.array(self.B, dtype=object)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Fit method: it calls FeedForward and Backpropagation methods\n",
    "    '''\n",
    "    def Fit(self, X_train, Y_train, epochs):            \n",
    "        print('Start fitting...')\n",
    "        '''\n",
    "        Input layer\n",
    "        '''\n",
    "        self.X = X_train\n",
    "        self.Y = Y_train\n",
    "        accurations= []\n",
    "        \n",
    "        '''\n",
    "        We now initialize the Network by retrieving the Hidden Layers and concatenating them \n",
    "        '''\n",
    "        print('Model recap: \\n')\n",
    "        print('You are fitting an ANN with the following amount of layers: ', len(self.HiddenLayer))\n",
    "        \n",
    "        \n",
    "        for i in range(0, len(self.HiddenLayer)) :\n",
    "            \n",
    "            print('Layer ', i+1)\n",
    "            print('Number of neurons: ', self.HiddenLayer[i][0])\n",
    "            if i==0:\n",
    "                # We now try to use the He et al. Initialization from ArXiv:1502.01852\n",
    "                self.w.append( np.random.randn(self.HiddenLayer[i][0] , self.X.shape[1])/np.sqrt(2/self.X.shape[1]) )\n",
    "                self.b.append( np.random.randn(self.HiddenLayer[i][0])/np.sqrt(2/self.X.shape[1]))\n",
    "                # Old initialization\n",
    "                #self.w.append(2 * np.random.rand(self.HiddenLayer[i][0] , self.X.shape[1]) - 0.5)\n",
    "                #self.b.append(np.random.rand(self.HiddenLayer[i][0]))\n",
    "            \n",
    "                # Initialize the Activation function\n",
    "                for act in Activation_function.list_act():\n",
    "                    if self.HiddenLayer[i][1] == act :\n",
    "                        self.phi.append(Activation_function.get_act(act))\n",
    "                        print('\\tActivation: ', act)\n",
    "            \n",
    "            else :\n",
    "                # We now try to use the He et al. Initialization from ArXiv:1502.01852\n",
    "                self.w.append( np.random.randn(self.HiddenLayer[i][0] , self.HiddenLayer[i-1][0] )/np.sqrt(2/self.HiddenLayer[i-1][0]))\n",
    "                self.b.append( np.random.randn(self.HiddenLayer[i][0])/np.sqrt(2/self.HiddenLayer[i-1][0]))\n",
    "                # Old initialization\n",
    "                #self.w.append(2*np.random.rand(self.HiddenLayer[i][0] , self.HiddenLayer[i-1][0] ) - 0.5)\n",
    "                #self.b.append(np.random.rand(self.HiddenLayer[i][0]))\n",
    "                \n",
    "                # Initialize the Activation function\n",
    "                for act in Activation_function.list_act():\n",
    "                    if self.HiddenLayer[i][1] == act :\n",
    "                        self.phi.append(Activation_function.get_act(act))\n",
    "                        print('\\tActivation: ', act)\n",
    "            \n",
    "        '''\n",
    "        Now we start the Loop over the training dataset\n",
    "        '''  \n",
    "        for epoch in range (0, epochs):\n",
    "            print(\"Epoch : \", epoch + 1)\n",
    "            for I in range(0, self.X.shape[0]): # loop over the training set\n",
    "                '''\n",
    "                Now we start the feed forward\n",
    "                '''  \n",
    "                self.z = []\n",
    "\n",
    "                self.z.append( self.FeedForward(self.w[0], self.b[0], self.phi[0], self.X[I]) ) # First layers\n",
    "\n",
    "                for i in range(1, len(self.HiddenLayer)): #Looping over layers\n",
    "                    self.z.append( self.FeedForward(self.w[i] , self.b[i], self.phi[i], self.z[i-1] ) )\n",
    "\n",
    "\n",
    "                '''\n",
    "                Here we backpropagate\n",
    "                '''      \n",
    "                self.w, self.b  = self.BackPropagation(self.X[I], self.z, self.Y.iloc[I], self.w, self.b, self.phi)\n",
    "\n",
    "                '''\n",
    "                Compute cost function\n",
    "                ''' \n",
    "                self.mu.append(\n",
    "                    (1/2) * np.dot(self.z[len(self.z)-1] - self.Y.iloc[I], self.z[len(self.z)-1] - self.Y.iloc[I]) \n",
    "                )\n",
    "                \n",
    "            prediction = self.get_accuration(X_train)\n",
    "            prediction[np.isnan(prediction)] = 0\n",
    "            print(\"Accuracy : \", accuracy_score(y_train, prediction))\n",
    "            accurations.append(accuracy_score(y_train, prediction))\n",
    "            \n",
    "        return accurations\n",
    "            \n",
    "        print('Fit done. \\n')\n",
    "        \n",
    "\n",
    "    \n",
    "    '''\n",
    "    predict method\n",
    "    '''\n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        print('Starting predictions...')\n",
    "        \n",
    "        self.pred = []\n",
    "        self.XX = X_test\n",
    "        \n",
    "        for I in range(0, self.XX.shape[0]): # loop over the training set\n",
    "            \n",
    "            '''\n",
    "            Now we start the feed forward\n",
    "            '''  \n",
    "            self.z = []\n",
    "            \n",
    "            self.z.append(self.FeedForward(self.w[0] , self.b[0], self.phi[0], self.XX[I])) #First layer\n",
    "    \n",
    "            for i in range(1, len(self.HiddenLayer)) : # loop over the layers\n",
    "                self.z.append( self.FeedForward(self.w[i] , self.b[i], self.phi[i], self.z[i-1]))\n",
    "       \n",
    "            # Append the prediction;\n",
    "            # We now need a binary classifier; we this apply an Heaviside Theta and we set to 0.5 the threshold\n",
    "            # if y < 0.5 the output is zero, otherwise is zero\n",
    "            self.pred.append( np.heaviside(  self.z[-1] - 0.5, 1)[0] ) # NB: self.z[-1]  is the last element of the self.z list\n",
    "        \n",
    "        print('Predictions done. \\n')\n",
    "\n",
    "        return np.array(self.pred)\n",
    "    \n",
    "    \n",
    "    def get_accuration(self, X):\n",
    "        self.pred = []\n",
    "        self.XX = X\n",
    "        \n",
    "        for I in range(0, self.XX.shape[0]): # loop over the training set\n",
    "            \n",
    "            '''\n",
    "            Now we start the feed forward\n",
    "            '''  \n",
    "            self.z = []\n",
    "            \n",
    "            self.z.append(self.FeedForward(self.w[0] , self.b[0], self.phi[0], self.XX[I])) #First layer\n",
    "    \n",
    "            for i in range(1, len(self.HiddenLayer)) : # loop over the layers\n",
    "                self.z.append( self.FeedForward(self.w[i] , self.b[i], self.phi[i], self.z[i-1]))\n",
    "       \n",
    "            # Append the prediction;\n",
    "            # We now need a binary classifier; we this apply an Heaviside Theta and we set to 0.5 the threshold\n",
    "            # if y < 0.5 the output is zero, otherwise is zero\n",
    "            self.pred.append( np.heaviside(  self.z[-1] - 0.5, 1)[0] ) # NB: self.z[-1]  is the last element of the self.z list\n",
    "\n",
    "        return np.array(self.pred)\n",
    "        \n",
    "   \n",
    "    '''\n",
    "    We need a method to retrieve the accuracy for each training data to follow the learning of the ANN\n",
    "    '''\n",
    "    def get_accuracy(self):\n",
    "        return np.array(self.mu)\n",
    "    # This is the averaged version\n",
    "    def get_avg_accuracy(self):\n",
    "        import math\n",
    "        self.batch_loss = []\n",
    "        for i in range(0, 10):\n",
    "            self.loss_avg = 0\n",
    "            # To set the batch in 10 element/batch we use math.ceil method\n",
    "            # int(math.ceil((self.X.shape[0]-10) / 10.0))    - 1\n",
    "            for m in range(0, (int(math.ceil((self.X.shape[0]-10) / 10.0))   )-1):\n",
    "                #self.loss_avg += self.mu[60*i+m]/60\n",
    "                self.loss_avg += self.mu[(int(math.ceil((self.X.shape[0]-10) / 10.0)) )*i + m]/(int(math.ceil((self.X.shape[0]-10) / 10.0)) )\n",
    "            self.batch_loss.append(self.loss_avg)\n",
    "        return np.array(self.batch_loss)\n",
    "    \n",
    "    '''\n",
    "    Method to set the learning rate\n",
    "    '''\n",
    "    def set_learning_rate(self, et=1):\n",
    "        self.eta = et\n",
    "        \n",
    "        \n",
    "'''\n",
    "layers class\n",
    "'''\n",
    "class layers :\n",
    "    '''\n",
    "    Layer method: used to call standar layers to add. \n",
    "    Easily generalizable to more general layers (Pooling and Convolutional layers)\n",
    "    '''        \n",
    "    def layer(p=4, activation = 'ReLU'):\n",
    "        return (p, activation)\n",
    "\n",
    "'''\n",
    "Activation functions class\n",
    "'''\n",
    "class Activation_function(DeepNeuralNetwork):\n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        \n",
    "    '''\n",
    "    Define the sigmoid activator; we ask if we want the sigmoid or its derivative\n",
    "    '''\n",
    "    def sigmoid_act(x, der=False):\n",
    "        if (der==True) : #derivative of the sigmoid\n",
    "            f = 1/(1+ np.exp(- x))*(1-1/(1+ np.exp(- x)))\n",
    "        else : # sigmoid\n",
    "            f = 1/(1+ np.exp(- x))\n",
    "        return f\n",
    "\n",
    "    '''\n",
    "    Define the Rectifier Linear Unit (ReLU)\n",
    "    '''\n",
    "    def ReLU_act(x, der=False):\n",
    "        if (der == True): # the derivative of the ReLU is the Heaviside Theta\n",
    "            f = np.heaviside(x, 1)\n",
    "        else :\n",
    "            f = np.maximum(x, 0)\n",
    "        return f\n",
    "    \n",
    "    def list_act():\n",
    "        return ['sigmoid', 'ReLU']\n",
    "    \n",
    "    def get_act(string = 'ReLU'):\n",
    "        if string == 'ReLU':\n",
    "            return ReLU_act\n",
    "        elif string == 'sigmoid':\n",
    "            return sigmoid_act\n",
    "        else :\n",
    "            return sigmoid_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931714c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_acc_train = {}\n",
    "dict_acc_test = {}\n",
    "dict_rec_train = {}\n",
    "dict_rec_test = {}\n",
    "\n",
    "epoch = [100, 150, 200]\n",
    "learning_rate = [0.01, 0.001, 0.0001]\n",
    "random_state = [0, 42]\n",
    "\n",
    "\n",
    "for i in epoch:\n",
    "    for j in learning_rate:\n",
    "        for k in random_state:\n",
    "            undersample = RandomUnderSampling(random_state=k)\n",
    "            X_under, y_under = undersample.fit(X, y)\n",
    "            X_train, X_test, y_train, y_test = pp.split_dataset(X_under, y_under)\n",
    "            X_train_scaled = pp.min_max_scaller(X_train)\n",
    "            X_test_scaled = pp.min_max_scaller(X_test)\n",
    "            \n",
    "            \n",
    "            \n",
    "            model = DeepNeuralNetwork()\n",
    "            model.add(layers.layer(11, 'ReLU'))\n",
    "            model.add(layers.layer(11, 'ReLU'))\n",
    "            model.add(layers.layer(11, 'ReLU'))\n",
    "            model.add(layers.layer(11, 'ReLU'))\n",
    "            # model.add(layers.layer(11, 'ReLU'))\n",
    "            model.add(layers.layer(1, 'sigmoid'))\n",
    "\n",
    "            model.set_learning_rate(j)\n",
    "\n",
    "            epoch = i\n",
    "\n",
    "            strings = 'epoch '+str(i)+', lr '+str(j)+', rs '+str(k)\n",
    "\n",
    "            dict_acc_train[strings] = model.Fit(X_train_scaled, y_train, epoch)\n",
    "            predictions_train = model.predict(X_train_scaled)\n",
    "            dict_rec_train[strings] = recall_score(y_train, predictions_train)\n",
    "            \n",
    "            acc_val = model.get_accuracy()\n",
    "            acc_avg_val = model.get_avg_accuracy()\n",
    "\n",
    "            predictions_test = model.predict(X_test_scaled)\n",
    "            dict_acc_test[strings] = accuracy_score(y_test, predictions_test)\n",
    "            dict_rec_test[strings] = recall_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf69677",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e7910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_rec_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ddd44c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6518a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_rec_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca6592",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5046871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(0,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c029b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, dict_acc_train['epoch 200, lr 0.01, rs 0'], label = \"lr 0.01, rs 0\")\n",
    "plt.plot(x, dict_acc_train['epoch 200, lr 0.01, rs 42'], label = \"lr 0.01, rs 42\")\n",
    "plt.plot(x, dict_acc_train['epoch 200, lr 0.001, rs 0'], label = \"lr 0.001, rs 0\")\n",
    "plt.plot(x, dict_acc_train['epoch 200, lr 0.001, rs 42'], label = \"lr 0.001, rs 42\")\n",
    "plt.plot(x, dict_acc_train['epoch 200, lr 0.0001, rs 0'], label = \"lr 0.0001, rs 0\")\n",
    "plt.plot(x, dict_acc_train['epoch 200, lr 0.0001, rs 42'], label = \"lr 0.0001, rs 42\")\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38226c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8107913",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117312e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c785f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad382f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
